{\rtf1\ansi\ansicpg1252\cocoartf1404\cocoasubrtf470
{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fnil\fcharset0 Menlo-Regular;\f2\fnil\fcharset0 Monaco;
}
{\colortbl;\red255\green255\blue255;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 Step 1 : Stop words taken from the below site. \
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0
{\field{\*\fldinst{HYPERLINK "http://www.ranks.nl/stopwords"}}{\fldrslt 
\f1\fs22 \cf0 \CocoaLigature0 http://www.ranks.nl/stopwords}}
\f1\fs22 \CocoaLigature0 \
\
Step 2 : Above words are saved in stopwords.txt and placed in Unix Server by using sftp client-cyber duck.\
/home/012/a/ax/axp161730\
\
Step 3 : Put this in hdfs server. (It is already placed in this folder)\
hdfs dfs -put ./stopwords.txt /user/axp161730/assignment_2/part1\
\
Step 4 : Remove output directory if already exists.\
hdfs dfs -rm -r -f /user/axp161730/wordcount1\
\
Step 5 : Put the latest jar file in hdfs server and run the below command.\
\
hadoop jar WordCount.jar WordCount.WordCount.
\f2 \CocoaLigature1 WordCount_copy
\f1 \CocoaLigature0  /user/axp161730/assignment_1/part2 /user/axp161730/wordcount1\
\
Step 6 : Check the results in /user/axp161730/wordcount1/part-r-00000\
hdfs dfs -cat /user/axp161730/wordcount1/part-r-00000\
}