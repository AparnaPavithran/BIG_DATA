{\rtf1\ansi\ansicpg1252\cocoartf1504
{\fonttbl\f0\fnil\fcharset0 Menlo-Bold;\f1\fnil\fcharset0 Menlo-Regular;\f2\fnil\fcharset0 Menlo-Italic;
}
{\colortbl;\red255\green255\blue255;\red13\green95\blue24;\red242\green242\blue242;\red38\green38\blue38;
\red19\green112\blue166;\red83\green83\blue83;\red79\green143\blue160;\red50\green91\blue142;\red53\green145\blue93;
\red124\green19\blue2;}
{\*\expandedcolortbl;\csgray\c100000;\cssrgb\c0\c43922\c12549;\cssrgb\c96078\c96078\c96078;\cssrgb\c20000\c20000\c20000;
\cssrgb\c5490\c51765\c70980;\cssrgb\c40000\c40000\c40000;\cssrgb\c37647\c62745\c69020;\cssrgb\c25098\c43922\c62745;\cssrgb\c25098\c62745\c43922;
\cssrgb\c56471\c12549\c0;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\sl400\partightenfactor0

\f0\b\fs24 \cf2 \cb3 \expnd0\expndtw0\kerning0
import
\f1\b0 \cf4  
\f0\b \cf5 org.apache.spark.ml.Pipeline
\f1\b0 \cf4 \

\f0\b \cf2 import
\f1\b0 \cf4  
\f0\b \cf5 org.apache.spark.ml.classification.DecisionTreeClassificationModel
\f1\b0 \cf4 \

\f0\b \cf2 import
\f1\b0 \cf4  
\f0\b \cf5 org.apache.spark.ml.classification.DecisionTreeClassifier
\f1\b0 \cf4 \

\f0\b \cf2 import
\f1\b0 \cf4  
\f0\b \cf5 org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator
\f1\b0 \cf4 \

\f0\b \cf2 import
\f1\b0 \cf4  
\f0\b \cf5 org.apache.spark.ml.feature.
\f1\b0 \cf6 \{
\f0\b \cf5 IndexToString
\f1\b0 \cf6 ,\cf4  
\f0\b \cf5 StringIndexer
\f1\b0 \cf6 ,\cf4  
\f0\b \cf5 VectorIndexer
\f1\b0 \cf6 \}\cf4 \
\

\f2\i \cf7 // Load the data stored in LIBSVM format as a DataFrame.
\f1\i0 \cf4 \

\f0\b \cf2 val
\f1\b0 \cf4  data 
\f0\b \cf2 =
\f1\b0 \cf4  spark\cf6 .\cf4 read\cf6 .\cf4 format\cf6 (\cf8 "libsvm"\cf6 ).\cf4 load\cf6 (\cf8 "sentiment labelled sentences"\cf6 )\cf4 \
\

\f2\i \cf7 // Index labels, adding metadata to the label column.
\f1\i0 \cf4 \

\f2\i \cf7 // Fit on whole dataset to include all labels in index.
\f1\i0 \cf4 \

\f0\b \cf2 val
\f1\b0 \cf4  labelIndexer 
\f0\b \cf2 =
\f1\b0 \cf4  
\f0\b \cf2 new
\f1\b0 \cf4  
\f0\b \cf5 StringIndexer
\f1\b0 \cf6 ().\cf4 setInputCol\cf6 (\cf8 "label"\cf6 ).\cf4 setOutputCol\cf6 (\cf8 "indexedLabel"\cf6 ).\cf4 fit\cf6 (\cf4 data\cf6 )\cf4 \

\f2\i \cf7 // Automatically identify categorical features, and index them.
\f1\i0 \cf4 \

\f0\b \cf2 val
\f1\b0 \cf4  featureIndexer 
\f0\b \cf2 =
\f1\b0 \cf4  
\f0\b \cf2 new
\f1\b0 \cf4  
\f0\b \cf5 VectorIndexer
\f1\b0 \cf6 ().\cf4 setInputCol\cf6 (\cf8 "features"\cf6 ).\cf4 setOutputCol\cf6 (\cf8 "indexedFeatures"\cf6 ).\cf4 setMaxCategories\cf6 (\cf9 4\cf6 ).\cf4 fit\cf6 (\cf4 data\cf6 )\
\cf4  
\f2\i \cf7 // features with > 4 distinct values are treated as continuous.
\f1\i0 \cf4 \
\

\f2\i \cf7 // Split the data into training and test sets (30% held out for testing).
\f1\i0 \cf4 \

\f0\b \cf2 val
\f1\b0 \cf4  
\f0\b \cf5 Array
\f1\b0 \cf6 (\cf4 trainingData\cf6 ,\cf4  testData\cf6 )\cf4  
\f0\b \cf2 =
\f1\b0 \cf4  data\cf6 .\cf4 randomSplit\cf6 (
\f0\b \cf5 Array
\f1\b0 \cf6 (\cf9 0.7\cf6 ,\cf4  \cf9 0.3\cf6 ))\cf4 \
\

\f2\i \cf7 // Train a DecisionTree model.
\f1\i0 \cf4 \

\f0\b \cf2 val
\f1\b0 \cf4  dt 
\f0\b \cf2 =
\f1\b0 \cf4  
\f0\b \cf2 new
\f1\b0 \cf4  
\f0\b \cf5 DecisionTreeClassifier
\f1\b0 \cf6 ().\cf4 setLabelCol\cf6 (\cf8 "indexedLabel"\cf6 ).\cf4 setFeaturesCol\cf6 (\cf8 "indexedFeatures"\cf6 )\cf4 \
\

\f2\i \cf7 // Convert indexed labels back to original labels.
\f1\i0 \cf4 \

\f0\b \cf2 val
\f1\b0 \cf4  labelConverter 
\f0\b \cf2 =
\f1\b0 \cf4  
\f0\b \cf2 new
\f1\b0 \cf4  
\f0\b \cf5 IndexToString
\f1\b0 \cf6 ().\cf4 setInputCol\cf6 (\cf8 "prediction"\cf6 ).\cf4 setOutputCol\cf6 (\cf8 "predictedLabel"\cf6 ).\cf4 setLabels\cf6 (\cf4 labelIndexer\cf6 .\cf4 labels\cf6 )\cf4 \
\

\f2\i \cf7 // Chain indexers and tree in a Pipeline.
\f1\i0 \cf4 \

\f0\b \cf2 val
\f1\b0 \cf4  pipeline 
\f0\b \cf2 =
\f1\b0 \cf4  
\f0\b \cf2 new
\f1\b0 \cf4  
\f0\b \cf5 Pipeline
\f1\b0 \cf6 ().\cf4 setStages\cf6 (
\f0\b \cf5 Array
\f1\b0 \cf6 (\cf4 labelIndexer\cf6 ,\cf4  featureIndexer\cf6 ,\cf4  dt\cf6 ,\cf4  labelConverter\cf6 ))\cf4 \
\

\f2\i \cf7 // Train model. This also runs the indexers.
\f1\i0 \cf4 \

\f0\b \cf2 val
\f1\b0 \cf4  model 
\f0\b \cf2 =
\f1\b0 \cf4  pipeline\cf6 .\cf4 fit\cf6 (\cf4 trainingData\cf6 )\cf4 \
\

\f2\i \cf7 // Make predictions.
\f1\i0 \cf4 \

\f0\b \cf2 val
\f1\b0 \cf4  predictions 
\f0\b \cf2 =
\f1\b0 \cf4  model\cf6 .\cf4 transform\cf6 (\cf4 testData\cf6 )\cf4 \
\

\f2\i \cf7 // Select example rows to display.
\f1\i0 \cf4 \
predictions\cf6 .\cf4 select\cf6 (\cf8 "predictedLabel"\cf6 ,\cf4  \cf8 "label"\cf6 ,\cf4  \cf8 "features"\cf6 ).\cf4 show\cf6 (\cf9 5\cf6 )\cf4 \
\

\f2\i \cf7 // Select (prediction, true label) and compute test error.
\f1\i0 \cf4 \

\f0\b \cf2 val
\f1\b0 \cf4  evaluator 
\f0\b \cf2 =
\f1\b0 \cf4  
\f0\b \cf2 new
\f1\b0 \cf4  
\f0\b \cf5 MulticlassClassificationEvaluator
\f1\b0 \cf6 ().\cf4 setLabelCol\cf6 (\cf8 "indexedLabel"\cf6 ).\cf4 setPredictionCol\cf6 (\cf8 "prediction"\cf6 ).\cf4 setMetricName\cf6 (\cf8 "accuracy"\cf6 )\cf4 \

\f0\b \cf2 val
\f1\b0 \cf4  accuracy 
\f0\b \cf2 =
\f1\b0 \cf4  evaluator\cf6 .\cf4 evaluate\cf6 (\cf4 predictions\cf6 )\cf4 \
println\cf6 (\cf8 "Test Error = "\cf4  \cf6 +\cf4  \cf6 (\cf9 1.0\cf4  \cf6 -\cf4  accuracy\cf6 ))\cf4 \
\

\f0\b \cf2 val
\f1\b0 \cf4  treeModel 
\f0\b \cf2 =
\f1\b0 \cf4  model\cf6 .\cf4 stages\cf6 (\cf9 2\cf6 ).\cf4 asInstanceOf\cf6 [\cf10 DecisionTreeClassificationModel\cf6 ]\cf4 \
println\cf6 (\cf8 "Learned classification tree model:\\n"\cf4  \cf6 +\cf4  treeModel\cf6 .\cf4 toDebugString\cf6 )\cf4 \
}